{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lg-W9D5t7QMp",
        "outputId": "5b765f6c-404d-4820-d41d-9760e0c11ea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "!pip install nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import spacy\n",
        "\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45M2nTYd8k4I",
        "outputId": "f060dbb3-c85e-4e35-d755-65557e63f227"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_antonyms(word):\n",
        "  synonyms = wordnet.synsets(word)\n",
        "  antonyms = []\n",
        "  for synset in synonyms:\n",
        "    for lemma in synset.lemmas():\n",
        "      for antonym in lemma.antonyms():\n",
        "        antonyms.append(antonym.name())\n",
        "  return list(set(antonyms))  # Remove duplicates"
      ],
      "metadata": {
        "id": "xTAowLU2-U8l"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"large\", \"happy\", \"beautiful\", \"hot\", \"interesting\", \"blessed\"]\n",
        "for word in words:\n",
        "  antonyms = get_antonyms(word)\n",
        "  if antonyms:\n",
        "    print(f\"Antonyms for '{word}': {', '.join(antonyms)}\")\n",
        "  else:\n",
        "    print(f\"No antonyms found for '{word}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scBy-EFx-YAl",
        "outputId": "b3c2e1c5-13f3-43f7-c0ad-b7c6eddc385b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Antonyms for 'large': little, small\n",
            "Antonyms for 'happy': unhappy\n",
            "Antonyms for 'beautiful': ugly\n",
            "Antonyms for 'hot': cold\n",
            "Antonyms for 'interesting': bore, uninteresting\n",
            "Antonyms for 'blessed': curse, cursed, desecrate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = SnowballStemmer(\"spanish\")\n",
        "word =\"Cerrar\"\n",
        "stemmed_word = stemmer.stem(word)\n",
        "print(\"Stemmed word of '{}' is: {}\".format(word, stemmed_word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ibq8JuAOCYtm",
        "outputId": "ae21d7c1-1ae7-4dea-8ba3-17313ccb7ae5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed word of 'Cerrar' is: cerr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_word(word, pos=None):\n",
        "  lemma = wordnet.morphy(word, pos)\n",
        "  return lemma if lemma else word"
      ],
      "metadata": {
        "id": "nacVGKuGChL3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"running\", \"happier\", \"beautiful\", \"caliente\", \"fascinante\"]\n",
        "for word in words:\n",
        "  lemmas = [lemmatize_word(word, pos) for pos in ['n', 'v', 'a', 'r']]\n",
        "  print(f\"Lemmas for '{word}': {', '.join(lemmas)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_GyVjTiCv98",
        "outputId": "81d0b1c3-01c2-4beb-d3c0-2bb32a8619d4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmas for 'running': running, run, running, running\n",
            "Lemmas for 'happier': happier, happier, happy, happier\n",
            "Lemmas for 'beautiful': beautiful, beautiful, beautiful, beautiful\n",
            "Lemmas for 'caliente': caliente, caliente, caliente, caliente\n",
            "Lemmas for 'fascinante': fascinante, fascinante, fascinante, fascinante\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"My dream car is a sleek sports car that accelerates like a rocket and hugs corners with precision.\"\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "tagged = nltk.pos_tag(tokens)\n",
        "print(\"PoS Tagging:\", tagged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0yNRUhbDudr",
        "outputId": "96833d19-9be4-44c8-a39a-a820b88fc355"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PoS Tagging: [('My', 'PRP$'), ('dream', 'NN'), ('car', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('sleek', 'JJ'), ('sports', 'NNS'), ('car', 'NN'), ('that', 'WDT'), ('accelerates', 'VBZ'), ('like', 'IN'), ('a', 'DT'), ('rocket', 'NN'), ('and', 'CC'), ('hugs', 'JJ'), ('corners', 'NNS'), ('with', 'IN'), ('precision', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The Nissan GT-R, a legendary Japanese supercar, combines awe-inspiring performance with cutting-edge technology to deliver an exhilarating driving experience.\"\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "tagged = nltk.pos_tag(tokens)\n",
        "named_entities = nltk.ne_chunk(tagged)\n",
        "print(\"Named Entity Recognition:\", named_entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9kSqAfCHRn0",
        "outputId": "7b5f6eac-63a4-4bd9-f5da-720b8aad3af2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named Entity Recognition: (S\n",
            "  The/DT\n",
            "  (ORGANIZATION Nissan/NNP)\n",
            "  GT-R/NNP\n",
            "  ,/,\n",
            "  a/DT\n",
            "  legendary/JJ\n",
            "  (GPE Japanese/JJ)\n",
            "  supercar/NN\n",
            "  ,/,\n",
            "  combines/NNS\n",
            "  awe-inspiring/JJ\n",
            "  performance/NN\n",
            "  with/IN\n",
            "  cutting-edge/JJ\n",
            "  technology/NN\n",
            "  to/TO\n",
            "  deliver/VB\n",
            "  an/DT\n",
            "  exhilarating/VBG\n",
            "  driving/NN\n",
            "  experience/NN\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "sentence = \"The Ferrari 718, with its mid-engine layout and thrilling performance, offers a taste of Ferrari's racing heritage in a more compact and agile package.\"\n",
        "doc = nlp(sentence)"
      ],
      "metadata": {
        "id": "6N7oXFQHIePE"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dependency Parsing:\")\n",
        "for token in doc:\n",
        "    print(token.text, token.dep_, token.head.text)\n",
        "\n",
        "print(\"\\nConstituency Parsing:\")\n",
        "for token in doc:\n",
        "    print(token.text, token.pos_, token.tag_, token.dep_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bxra_7dtIv8L",
        "outputId": "9494c087-6c10-4711-862d-7b20bc45300e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependency Parsing:\n",
            "The det Ferrari\n",
            "Ferrari nsubj offers\n",
            "718 nummod Ferrari\n",
            ", punct Ferrari\n",
            "with prep Ferrari\n",
            "its poss layout\n",
            "mid amod layout\n",
            "- amod layout\n",
            "engine amod layout\n",
            "layout pobj with\n",
            "and cc layout\n",
            "thrilling amod performance\n",
            "performance conj layout\n",
            ", punct Ferrari\n",
            "offers ROOT offers\n",
            "a det taste\n",
            "taste dobj offers\n",
            "of prep taste\n",
            "Ferrari poss heritage\n",
            "'s case Ferrari\n",
            "racing compound heritage\n",
            "heritage pobj of\n",
            "in prep offers\n",
            "a det package\n",
            "more advmod compact\n",
            "compact amod package\n",
            "and cc compact\n",
            "agile conj compact\n",
            "package pobj in\n",
            ". punct offers\n",
            "\n",
            "Constituency Parsing:\n",
            "The DET DT det\n",
            "Ferrari PROPN NNP nsubj\n",
            "718 NUM CD nummod\n",
            ", PUNCT , punct\n",
            "with ADP IN prep\n",
            "its PRON PRP$ poss\n",
            "mid ADJ JJ amod\n",
            "- ADJ JJ amod\n",
            "engine ADJ JJ amod\n",
            "layout NOUN NN pobj\n",
            "and CCONJ CC cc\n",
            "thrilling NOUN NN amod\n",
            "performance NOUN NN conj\n",
            ", PUNCT , punct\n",
            "offers VERB VBZ ROOT\n",
            "a DET DT det\n",
            "taste NOUN NN dobj\n",
            "of ADP IN prep\n",
            "Ferrari PROPN NNP poss\n",
            "'s PART POS case\n",
            "racing NOUN NN compound\n",
            "heritage NOUN NN pobj\n",
            "in ADP IN prep\n",
            "a DET DT det\n",
            "more ADV RBR advmod\n",
            "compact ADJ JJ amod\n",
            "and CCONJ CC cc\n",
            "agile ADJ JJ conj\n",
            "package NOUN NN pobj\n",
            ". PUNCT . punct\n"
          ]
        }
      ]
    }
  ]
}