{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNq6sjsMX5cA2UjpSy++9B2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManishSuhas0026/NLP/blob/main/Manesh_530_Lab_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lg-W9D5t7QMp",
        "outputId": "5b765f6c-404d-4820-d41d-9760e0c11ea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "!pip install nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import spacy\n",
        "\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45M2nTYd8k4I",
        "outputId": "f060dbb3-c85e-4e35-d755-65557e63f227"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_antonyms(word):\n",
        "  synonyms = wordnet.synsets(word)\n",
        "  antonyms = []\n",
        "  for synset in synonyms:\n",
        "    for lemma in synset.lemmas():\n",
        "      for antonym in lemma.antonyms():\n",
        "        antonyms.append(antonym.name())\n",
        "  return list(set(antonyms))  # Remove duplicates"
      ],
      "metadata": {
        "id": "xTAowLU2-U8l"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"large\", \"happy\", \"beautiful\", \"hot\", \"interesting\", \"blessed\"]\n",
        "for word in words:\n",
        "  antonyms = get_antonyms(word)\n",
        "  if antonyms:\n",
        "    print(f\"Antonyms for '{word}': {', '.join(antonyms)}\")\n",
        "  else:\n",
        "    print(f\"No antonyms found for '{word}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scBy-EFx-YAl",
        "outputId": "b3c2e1c5-13f3-43f7-c0ad-b7c6eddc385b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Antonyms for 'large': little, small\n",
            "Antonyms for 'happy': unhappy\n",
            "Antonyms for 'beautiful': ugly\n",
            "Antonyms for 'hot': cold\n",
            "Antonyms for 'interesting': bore, uninteresting\n",
            "Antonyms for 'blessed': curse, cursed, desecrate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = SnowballStemmer(\"spanish\")\n",
        "word =\"Cerrar\"\n",
        "stemmed_word = stemmer.stem(word)\n",
        "print(\"Stemmed word of '{}' is: {}\".format(word, stemmed_word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ibq8JuAOCYtm",
        "outputId": "ae21d7c1-1ae7-4dea-8ba3-17313ccb7ae5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed word of 'Cerrar' is: cerr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_word(word, pos=None):\n",
        "  lemma = wordnet.morphy(word, pos)\n",
        "  return lemma if lemma else word"
      ],
      "metadata": {
        "id": "nacVGKuGChL3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"running\", \"happier\", \"beautiful\", \"caliente\", \"fascinante\"]\n",
        "for word in words:\n",
        "  lemmas = [lemmatize_word(word, pos) for pos in ['n', 'v', 'a', 'r']]\n",
        "  print(f\"Lemmas for '{word}': {', '.join(lemmas)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_GyVjTiCv98",
        "outputId": "81d0b1c3-01c2-4beb-d3c0-2bb32a8619d4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmas for 'running': running, run, running, running\n",
            "Lemmas for 'happier': happier, happier, happy, happier\n",
            "Lemmas for 'beautiful': beautiful, beautiful, beautiful, beautiful\n",
            "Lemmas for 'caliente': caliente, caliente, caliente, caliente\n",
            "Lemmas for 'fascinante': fascinante, fascinante, fascinante, fascinante\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"My dream car is a sleek sports car that accelerates like a rocket and hugs corners with precision.\"\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "tagged = nltk.pos_tag(tokens)\n",
        "print(\"PoS Tagging:\", tagged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0yNRUhbDudr",
        "outputId": "96833d19-9be4-44c8-a39a-a820b88fc355"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PoS Tagging: [('My', 'PRP$'), ('dream', 'NN'), ('car', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('sleek', 'JJ'), ('sports', 'NNS'), ('car', 'NN'), ('that', 'WDT'), ('accelerates', 'VBZ'), ('like', 'IN'), ('a', 'DT'), ('rocket', 'NN'), ('and', 'CC'), ('hugs', 'JJ'), ('corners', 'NNS'), ('with', 'IN'), ('precision', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The Nissan GT-R, a legendary Japanese supercar, combines awe-inspiring performance with cutting-edge technology to deliver an exhilarating driving experience.\"\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "tagged = nltk.pos_tag(tokens)\n",
        "named_entities = nltk.ne_chunk(tagged)\n",
        "print(\"Named Entity Recognition:\", named_entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9kSqAfCHRn0",
        "outputId": "7b5f6eac-63a4-4bd9-f5da-720b8aad3af2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named Entity Recognition: (S\n",
            "  The/DT\n",
            "  (ORGANIZATION Nissan/NNP)\n",
            "  GT-R/NNP\n",
            "  ,/,\n",
            "  a/DT\n",
            "  legendary/JJ\n",
            "  (GPE Japanese/JJ)\n",
            "  supercar/NN\n",
            "  ,/,\n",
            "  combines/NNS\n",
            "  awe-inspiring/JJ\n",
            "  performance/NN\n",
            "  with/IN\n",
            "  cutting-edge/JJ\n",
            "  technology/NN\n",
            "  to/TO\n",
            "  deliver/VB\n",
            "  an/DT\n",
            "  exhilarating/VBG\n",
            "  driving/NN\n",
            "  experience/NN\n",
            "  ./.)\n"
          ]
        }
      ]
    }
  ]
}