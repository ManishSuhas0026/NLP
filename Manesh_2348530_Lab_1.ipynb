{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMll4gndStbqqw46riWpQ/m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManishSuhas0026/NLP/blob/main/Manesh_2348530_Lab_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJCGMqKetnuI",
        "outputId": "09a86861-eaca-45dd-c8da-f7d0dac52e37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOgbozfUtHpD"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize, TweetTokenizer\n",
        "from nltk.tokenize import MWETokenizer, PunktSentenceTokenizer\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from textblob import TextBlob\n",
        "import spacy\n",
        "import gensim\n",
        "from keras.preprocessing.text import text_to_word_sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"In the vast world of artificial intelligence ðŸ¤–, understanding natural language processing (NLP) is crucial ðŸ§ . From sentiment analysis to language translation, NLP empowers machines to comprehend human language, enabling smoother interactions between humans and technology. However, NLP tasks often involve intricate challenges, such as handling punctuation marks, stop words, and negations ðŸ›‘.\""
      ],
      "metadata": {
        "id": "1rlgJSKftMew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens = word_tokenize(text)\n",
        "\n",
        "sent_tokens = sent_tokenize(text)"
      ],
      "metadata": {
        "id": "TLFxWSf0tUOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "punkt_tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
        "punct_tokens = punkt_tokenizer.tokenize(text)"
      ],
      "metadata": {
        "id": "rKsDTVq4t0YG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treebank_tokenizer = TreebankWordTokenizer()\n",
        "treebank_tokens = treebank_tokenizer.tokenize(text)\n",
        "\n",
        "tweet_tokenizer = TweetTokenizer()\n",
        "tweet_tokens = tweet_tokenizer.tokenize(text)\n",
        "\n",
        "mwe_tokenizer = MWETokenizer([('natural', 'language'), ('sentiment', 'analysis')])\n",
        "mwe_tokens = mwe_tokenizer.tokenize(word_tokenize(text))"
      ],
      "metadata": {
        "id": "p4z57lS1t2zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textblob_tokens = TextBlob(text).words\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(text)\n",
        "spacy_tokens = [token.text for token in doc]"
      ],
      "metadata": {
        "id": "jtbtdjBfuGmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gensim_tokens = gensim.utils.simple_preprocess(text)\n",
        "\n",
        "keras_tokens = text_to_word_sequence(text)"
      ],
      "metadata": {
        "id": "lxEJx8DbuKCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Word Tokens:\", word_tokens)\n",
        "print(\"\\nSentence Tokens:\", sent_tokens)\n",
        "print(\"\\nPunctuation-based Tokens:\", punct_tokens)\n",
        "print(\"\\nTreebank Word Tokens:\", treebank_tokens)\n",
        "print(\"\\nTweet Tokens:\", tweet_tokens)\n",
        "print(\"\\nMulti-Word Expression Tokens:\", mwe_tokens)\n",
        "print(\"\\nTextBlob Word Tokens:\", textblob_tokens)\n",
        "print(\"\\nspaCy Tokens:\", spacy_tokens)\n",
        "print(\"\\nGensim Tokens:\", gensim_tokens)\n",
        "print(\"\\nKeras Tokens:\", keras_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF0IvXe6uYBr",
        "outputId": "de86cbfa-0238-496b-b0c2-8ea9afa3b73a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Tokens: ['In', 'the', 'vast', 'world', 'of', 'artificial', 'intelligence', 'ðŸ¤–', ',', 'understanding', 'natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'crucial', 'ðŸ§ ', '.', 'From', 'sentiment', 'analysis', 'to', 'language', 'translation', ',', 'NLP', 'empowers', 'machines', 'to', 'comprehend', 'human', 'language', ',', 'enabling', 'smoother', 'interactions', 'between', 'humans', 'and', 'technology', '.', 'However', ',', 'NLP', 'tasks', 'often', 'involve', 'intricate', 'challenges', ',', 'such', 'as', 'handling', 'punctuation', 'marks', ',', 'stop', 'words', ',', 'and', 'negations', 'ðŸ›‘', '.']\n",
            "\n",
            "Sentence Tokens: ['In the vast world of artificial intelligence ðŸ¤–, understanding natural language processing (NLP) is crucial ðŸ§ .', 'From sentiment analysis to language translation, NLP empowers machines to comprehend human language, enabling smoother interactions between humans and technology.', 'However, NLP tasks often involve intricate challenges, such as handling punctuation marks, stop words, and negations ðŸ›‘.']\n",
            "\n",
            "Punctuation-based Tokens: ['In', 'the', 'vast', 'world', 'of', 'artificial', 'intelligence', 'ðŸ¤–,', 'understanding', 'natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'crucial', 'ðŸ§ .', 'From', 'sentiment', 'analysis', 'to', 'language', 'translation', ',', 'NLP', 'empowers', 'machines', 'to', 'comprehend', 'human', 'language', ',', 'enabling', 'smoother', 'interactions', 'between', 'humans', 'and', 'technology', '.', 'However', ',', 'NLP', 'tasks', 'often', 'involve', 'intricate', 'challenges', ',', 'such', 'as', 'handling', 'punctuation', 'marks', ',', 'stop', 'words', ',', 'and', 'negations', 'ðŸ›‘.']\n",
            "\n",
            "Treebank Word Tokens: ['In', 'the', 'vast', 'world', 'of', 'artificial', 'intelligence', 'ðŸ¤–', ',', 'understanding', 'natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'crucial', 'ðŸ§ .', 'From', 'sentiment', 'analysis', 'to', 'language', 'translation', ',', 'NLP', 'empowers', 'machines', 'to', 'comprehend', 'human', 'language', ',', 'enabling', 'smoother', 'interactions', 'between', 'humans', 'and', 'technology.', 'However', ',', 'NLP', 'tasks', 'often', 'involve', 'intricate', 'challenges', ',', 'such', 'as', 'handling', 'punctuation', 'marks', ',', 'stop', 'words', ',', 'and', 'negations', 'ðŸ›‘', '.']\n",
            "\n",
            "Tweet Tokens: ['In', 'the', 'vast', 'world', 'of', 'artificial', 'intelligence', 'ðŸ¤–', ',', 'understanding', 'natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'crucial', 'ðŸ§ ', '.', 'From', 'sentiment', 'analysis', 'to', 'language', 'translation', ',', 'NLP', 'empowers', 'machines', 'to', 'comprehend', 'human', 'language', ',', 'enabling', 'smoother', 'interactions', 'between', 'humans', 'and', 'technology', '.', 'However', ',', 'NLP', 'tasks', 'often', 'involve', 'intricate', 'challenges', ',', 'such', 'as', 'handling', 'punctuation', 'marks', ',', 'stop', 'words', ',', 'and', 'negations', 'ðŸ›‘', '.']\n",
            "\n",
            "Multi-Word Expression Tokens: ['In', 'the', 'vast', 'world', 'of', 'artificial', 'intelligence', 'ðŸ¤–', ',', 'understanding', 'natural_language', 'processing', '(', 'NLP', ')', 'is', 'crucial', 'ðŸ§ ', '.', 'From', 'sentiment_analysis', 'to', 'language', 'translation', ',', 'NLP', 'empowers', 'machines', 'to', 'comprehend', 'human', 'language', ',', 'enabling', 'smoother', 'interactions', 'between', 'humans', 'and', 'technology', '.', 'However', ',', 'NLP', 'tasks', 'often', 'involve', 'intricate', 'challenges', ',', 'such', 'as', 'handling', 'punctuation', 'marks', ',', 'stop', 'words', ',', 'and', 'negations', 'ðŸ›‘', '.']\n",
            "\n",
            "TextBlob Word Tokens: ['In', 'the', 'vast', 'world', 'of', 'artificial', 'intelligence', 'ðŸ¤–', 'understanding', 'natural', 'language', 'processing', 'NLP', 'is', 'crucial', 'ðŸ§ ', 'From', 'sentiment', 'analysis', 'to', 'language', 'translation', 'NLP', 'empowers', 'machines', 'to', 'comprehend', 'human', 'language', 'enabling', 'smoother', 'interactions', 'between', 'humans', 'and', 'technology', 'However', 'NLP', 'tasks', 'often', 'involve', 'intricate', 'challenges', 'such', 'as', 'handling', 'punctuation', 'marks', 'stop', 'words', 'and', 'negations', 'ðŸ›‘']\n",
            "\n",
            "spaCy Tokens: ['In', 'the', 'vast', 'world', 'of', 'artificial', 'intelligence', 'ðŸ¤–', ',', 'understanding', 'natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'crucial', 'ðŸ§ ', '.', 'From', 'sentiment', 'analysis', 'to', 'language', 'translation', ',', 'NLP', 'empowers', 'machines', 'to', 'comprehend', 'human', 'language', ',', 'enabling', 'smoother', 'interactions', 'between', 'humans', 'and', 'technology', '.', 'However', ',', 'NLP', 'tasks', 'often', 'involve', 'intricate', 'challenges', ',', 'such', 'as', 'handling', 'punctuation', 'marks', ',', 'stop', 'words', ',', 'and', 'negations', 'ðŸ›‘', '.']\n",
            "\n",
            "Gensim Tokens: ['in', 'the', 'vast', 'world', 'of', 'artificial', 'intelligence', 'understanding', 'natural', 'language', 'processing', 'nlp', 'is', 'crucial', 'from', 'sentiment', 'analysis', 'to', 'language', 'translation', 'nlp', 'empowers', 'machines', 'to', 'comprehend', 'human', 'language', 'enabling', 'smoother', 'interactions', 'between', 'humans', 'and', 'technology', 'however', 'nlp', 'tasks', 'often', 'involve', 'intricate', 'challenges', 'such', 'as', 'handling', 'punctuation', 'marks', 'stop', 'words', 'and', 'negations', 'for', 'instance', 'in', 'sentiment', 'analysis', 'the', 'presence', 'or', 'absence', 'of', 'negations', 'like', 'don', 'can', 'completely', 'alter', 'the', 'meaning', 'of', 'sentence', 'therefore', 'utilizing', 'advanced', 'tokenization', 'techniques', 'becomes', 'imperative', 'to', 'accurately', 'process', 'textual', 'data']\n",
            "\n",
            "Keras Tokens: ['in', 'the', 'vast', 'world', 'of', 'artificial', 'intelligence', 'ðŸ¤–', 'understanding', 'natural', 'language', 'processing', 'nlp', 'is', 'crucial', 'ðŸ§ ', 'from', 'sentiment', 'analysis', 'to', 'language', 'translation', 'nlp', 'empowers', 'machines', 'to', 'comprehend', 'human', 'language', 'enabling', 'smoother', 'interactions', 'between', 'humans', 'and', 'technology', 'however', 'nlp', 'tasks', 'often', 'involve', 'intricate', 'challenges', 'such', 'as', 'handling', 'punctuation', 'marks', 'stop', 'words', 'and', 'negations', 'ðŸ›‘', 'for', 'instance', 'in', 'sentiment', 'analysis', 'the', 'presence', 'or', 'absence', 'of', 'negations', 'like', \"'don't'\", 'can', 'completely', 'alter', 'the', 'meaning', 'of', 'a', 'sentence', 'therefore', 'utilizing', 'advanced', 'tokenization', 'techniques', 'becomes', 'imperative', 'to', 'accurately', 'process', 'textual', 'data']\n"
          ]
        }
      ]
    }
  ]
}